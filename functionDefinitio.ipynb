{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593bab71",
   "metadata": {},
   "source": [
    "# Modelo de regresión lineal \n",
    "\n",
    "### Carlos Alberto Mentado Reyes A01276065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5f9d990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9733d31",
   "metadata": {},
   "source": [
    " Primero definiré funciones necesarias, como costo, coeficiente de determinación etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "06ab5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de covarianza y correlación\n",
    "\n",
    "def covariance(x, y):\n",
    "    y_mean = y.mean()\n",
    "    x_mean = x.mean()\n",
    "    cov = 0\n",
    "    for i in range(len(x)):\n",
    "        cov += (x[i] - x_mean) * (y[i] - y_mean)\n",
    "\n",
    "    return cov / (len(x) - 1)\n",
    "\n",
    "def correlation(x, y):\n",
    "    return covariance(x, y) / (x.std() * y.std())\n",
    "\n",
    "def standardize(x):\n",
    "    return (x - x.mean()) / x.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a62d9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función predict y función costo \n",
    "\n",
    "def predict(x, w, b):\n",
    "    return w * x + b\n",
    "\n",
    "def cost(y, y_pred):\n",
    "    cost = 0\n",
    "    for i in range(0, len(y)):\n",
    "        cost += (y.iloc[i] - y_pred[i]) ** 2\n",
    "    return cost / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e4772ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función descenso de gradiente w y b \n",
    "\n",
    "def b_gradient_descent(x, w, b, lr,y):\n",
    "    n = len(x)\n",
    "    partial_b_sum = 0\n",
    "    for i in range(0, n):\n",
    "        partial_b_sum += (y.iloc[i] - b - (w*x.iloc[i])) * (-1)\n",
    "\n",
    "    partial_b = partial_b_sum * (2/n)\n",
    "\n",
    "    return b - lr*(partial_b)\n",
    "\n",
    "\n",
    "\n",
    "def w_gradient_descent(x, w, b, lr, y):\n",
    "    n = len(x)\n",
    "    partial_w_sum = 0\n",
    "    for i in range(0, n):\n",
    "        partial_w_sum += (y.iloc[i]-b-(w*x.iloc[i])) * ((-1)*x.iloc[i])\n",
    "    partial_w = partial_w_sum * (2/n)\n",
    "\n",
    "    return w - lr * partial_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f7409fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función general\n",
    "\n",
    "def trainModel(x, y, lr, max_iter):\n",
    "    tol = 1e-6\n",
    "    if len(x) != len(y):\n",
    "        print(\"size of arrays for features and targets do not match\")\n",
    "        return\n",
    "\n",
    "    np.random.seed(42)\n",
    "    w = 0.1\n",
    "    b = 0.1\n",
    "    model_cost = float(\"inf\")\n",
    "    iter_cost = float(\"inf\")\n",
    "\n",
    "    for i in range(0, max_iter):\n",
    "        predictions=[]\n",
    "\n",
    "        for j in range(0, len(x)):\n",
    "            predictions.append(predict(x.iloc[j], w, b))\n",
    "\n",
    "        print(f\"current cost: {iter_cost}\")\n",
    "        iter_cost = cost(y, predictions)\n",
    "        if abs(model_cost - iter_cost) < tol: \n",
    "            break\n",
    "        model_cost = iter_cost\n",
    "        w = w_gradient_descent(x, w, b, lr, y)\n",
    "        b = b_gradient_descent(x, w, b, lr, y)\n",
    "\n",
    "    return w, b\n",
    "\n",
    "def testModel(w, b, x, y):\n",
    "    predictions = []\n",
    "    for i in range(0, len(x)):\n",
    "        predictions.append(predict(x.iloc[i], w, b))\n",
    "    \n",
    "    results = cost(y, predictions)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "3958b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para entrenar y testear \n",
    "\n",
    "def linearModel(x_train, x_test, y_train, y_test, lr=0.1, max_iter=100):\n",
    "    print(\"Beggining training\")\n",
    "    print(f\"Max iterations: {max_iter}\")\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    w, b = trainModel(x_train, y_train, lr, max_iter)\n",
    "\n",
    "    results = testModel(w, b, x_test, y_test)\n",
    "\n",
    "    print(\"Final results:\")\n",
    "    print(f\"y = {np.mean(w)}x + {np.mean(b)}\")\n",
    "    print(f\"Final cost: {np.mean(results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "01ebf28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beggining training\n",
      "Max iterations: 100\n",
      "Learning rate: 0.1\n",
      "current cost: inf\n",
      "current cost: 16407849.959740626\n",
      "current cost: 10570977.863947988\n",
      "current cost: 6925621.522596398\n",
      "current cost: 4636039.335415845\n",
      "current cost: 3189948.007610361\n",
      "current cost: 2271620.175635188\n",
      "current cost: 1685378.3122367265\n",
      "current cost: 1309258.4062342688\n",
      "current cost: 1066808.1423447442\n",
      "current cost: 909833.3480442289\n",
      "current cost: 807785.3926811385\n",
      "current cost: 741197.0236247206\n",
      "current cost: 697599.2018673297\n",
      "current cost: 668966.6905937948\n",
      "current cost: 650110.9350925758\n",
      "current cost: 637663.2822971906\n",
      "current cost: 629428.1984422355\n",
      "current cost: 623969.7001825086\n",
      "current cost: 620345.598801783\n",
      "current cost: 617935.9332965757\n",
      "current cost: 616331.7306444171\n",
      "current cost: 615262.5930609788\n",
      "current cost: 614549.3883826123\n",
      "current cost: 614073.2391103422\n",
      "current cost: 613755.1347091094\n",
      "current cost: 613542.4924726266\n",
      "current cost: 613400.2778879764\n",
      "current cost: 613305.1254155939\n",
      "current cost: 613241.4387557933\n",
      "current cost: 613198.8000083183\n",
      "current cost: 613170.2460317017\n",
      "current cost: 613151.1203626082\n",
      "current cost: 613138.3077144333\n",
      "current cost: 613129.7231146679\n",
      "current cost: 613123.9707189173\n",
      "current cost: 613120.1157985475\n",
      "current cost: 613117.5322780967\n",
      "current cost: 613115.800742577\n",
      "current cost: 613114.6401810028\n",
      "current cost: 613113.8622922973\n",
      "current cost: 613113.3408872101\n",
      "current cost: 613112.9913943622\n",
      "current cost: 613112.7571312819\n",
      "current cost: 613112.600105947\n",
      "current cost: 613112.494853027\n",
      "current cost: 613112.4243032428\n",
      "current cost: 613112.3770149945\n",
      "current cost: 613112.3453188902\n",
      "current cost: 613112.324074072\n",
      "current cost: 613112.3098345915\n",
      "current cost: 613112.3002906245\n",
      "current cost: 613112.2938939069\n",
      "current cost: 613112.2896066577\n",
      "current cost: 613112.2867332739\n",
      "current cost: 613112.284807515\n",
      "current cost: 613112.2835168797\n",
      "current cost: 613112.282651914\n",
      "current cost: 613112.2820722344\n",
      "current cost: 613112.2816837524\n",
      "current cost: 613112.2814234081\n",
      "current cost: 613112.2812489386\n",
      "current cost: 613112.2811320192\n",
      "current cost: 613112.2810536679\n",
      "current cost: 613112.2810011627\n",
      "current cost: 613112.2809659779\n",
      "current cost: 613112.2809424005\n",
      "current cost: 613112.2809266008\n",
      "current cost: 613112.2809160136\n",
      "current cost: 613112.2809089192\n",
      "current cost: 613112.2809041652\n",
      "current cost: 613112.2809009798\n",
      "current cost: 613112.2808988454\n",
      "current cost: 613112.2808974151\n",
      "Final results:\n",
      "y = 213.69643835760027x + 3936.6303881816507\n",
      "Final cost: 262728.8198673007\n"
     ]
    }
   ],
   "source": [
    "#Pequeña prueba\n",
    "\n",
    "#Bases de datos a utilizar\n",
    "url = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/c19a904462482430170bfe2c718775ddb7dbb885/inst/extdata/penguins_raw.csv\"\n",
    "\n",
    "penguins = pd.read_csv(url).dropna()\n",
    "penguins_target = penguins[\"Body Mass (g)\"]\n",
    "penguins_feature = penguins[\"Culmen Length (mm)\"]\n",
    "penguins_feature = standardize(penguins_feature)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    penguins_feature, penguins_target, test_size=0.33, random_state=42\n",
    ")\n",
    "\n",
    "linearModel(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    0.1,\n",
    "    100\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48bd3b7",
   "metadata": {},
   "source": [
    "### El siguiente paso será pasar todo el modelo a un .py y permitir que se corra el modelo desde otro .py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
